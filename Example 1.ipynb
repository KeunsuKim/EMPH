{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shape Clustering and Persistence Analysis\n",
    "\n",
    "이 노트북은 기본 도형(원, 정사각형, 별, 삼각형)의 경계를 1차원 극좌표 곡선으로 변환하고, 퍼시스턴스 이미지를 활용해 군집화를 수행한 뒤 결과를 시각화/해석한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import image as mpimg\n",
    "\n",
    "import gudhi as gd\n",
    "from gudhi.representations.vector_methods import PersistenceImage\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from scipy.fft import fft\n",
    "from scipy.interpolate import PchipInterpolator\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "from skimage import measure\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.measure import label as sk_label, regionprops, regionprops_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"seaborn-v0_8\")\n",
    "np.random.seed(0)\n",
    "\n",
    "SUBJECTS = [\"circle\", \"square\", \"star\", \"triangle\"]\n",
    "SAMPLES_PER_CLASS = 100\n",
    "FOURIER_SAMPLES = 360\n",
    "FREQUENCIES = np.array([1, 2, 3, 4, 5])\n",
    "N_CLUSTERS = 5\n",
    "PERSISTENCE_DIRECTION = np.array([1.0, 1.0, 1.0, 1.0, 0.2], dtype=float)\n",
    "PERSISTENCE_ENDPOINT = np.zeros_like(PERSISTENCE_DIRECTION)\n",
    "PERSISTENCE_RESOLUTION = 50\n",
    "SHAPES_ROOT = \"shapes\"\n",
    "STAR_LABEL = SUBJECTS.index(\"star\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_1d_polar(file_path: str, K: int = FOURIER_SAMPLES) -> np.ndarray:\n",
    "    \"\"\"이미지를 각도-반지름 곡선 r(θ)으로 변환한다.\"\"\"\n",
    "    img = plt.imread(file_path).astype(float)\n",
    "\n",
    "    if img.ndim == 3:\n",
    "        img = rgb2gray(img)\n",
    "    if img.max() > 1:\n",
    "        img /= 255.0\n",
    "\n",
    "    threshold = threshold_otsu(img)\n",
    "    mask = img < threshold\n",
    "\n",
    "    lab = sk_label(mask)\n",
    "    regions = regionprops(lab)\n",
    "    if not regions:\n",
    "        raise ValueError(f\"No valid region found in {file_path!r}.\")\n",
    "    region = max(regions, key=lambda r: r.area)\n",
    "    cy, cx = region.centroid\n",
    "\n",
    "    contours = measure.find_contours(mask.astype(float), 0.5)\n",
    "    if not contours:\n",
    "        raise ValueError(f\"No contour detected in {file_path!r}.\")\n",
    "    contour = max(contours, key=len)\n",
    "\n",
    "    dy = contour[:, 0] - cy\n",
    "    dx = contour[:, 1] - cx\n",
    "    theta = np.mod(np.arctan2(dy, dx), 2 * np.pi)\n",
    "    radius = np.hypot(dx, dy)\n",
    "\n",
    "    order = np.argsort(theta)\n",
    "    theta = theta[order]\n",
    "    radius = radius[order]\n",
    "\n",
    "    if len(theta) > 1:\n",
    "        keep = [0]\n",
    "        for idx in range(1, len(theta)):\n",
    "            if theta[idx] - theta[keep[-1]] > 1e-8:\n",
    "                keep.append(idx)\n",
    "        theta = theta[keep]\n",
    "        radius = radius[keep]\n",
    "\n",
    "    theta_ext = np.concatenate([theta - 2 * np.pi, theta, theta + 2 * np.pi])\n",
    "    radius_ext = np.concatenate([radius, radius, radius])\n",
    "    interpolator = PchipInterpolator(theta_ext, radius_ext, extrapolate=False)\n",
    "\n",
    "    theta_new = np.linspace(0, 2 * np.pi, K, endpoint=False)\n",
    "    theta_query = ((theta_new - theta.min()) % (2 * np.pi)) + theta.min()\n",
    "    r_theta = interpolator(theta_query)\n",
    "    return np.clip(r_theta, 0.0, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_polar_dataset(subjects, root_dir, samples_per_class, K=FOURIER_SAMPLES):\n",
    "    total = len(subjects) * samples_per_class\n",
    "    data = np.zeros((total, K), dtype=float)\n",
    "    labels = np.zeros(total, dtype=int)\n",
    "    sample_ids = np.zeros(total, dtype=int)\n",
    "\n",
    "    for subject_idx, subject in enumerate(subjects):\n",
    "        for sample_idx in range(samples_per_class):\n",
    "            row = subject_idx * samples_per_class + sample_idx\n",
    "            file_path = os.path.join(root_dir, subject, f\"{sample_idx}.png\")\n",
    "            data[row] = convert_to_1d_polar(file_path, K=K)\n",
    "            labels[row] = subject_idx\n",
    "            sample_ids[row] = sample_idx\n",
    "    return data, labels, sample_ids\n",
    "\n",
    "\n",
    "data, labels, sample_ids = load_polar_dataset(SUBJECTS, SHAPES_ROOT, SAMPLES_PER_CLASS)\n",
    "print(f\"signals: {data.shape}, labels: {labels.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_persistence_diagram(signal, direction, endpoint):\n",
    "    max_freq = len(direction)\n",
    "    norm = np.sqrt(max_freq)\n",
    "    birth = (-endpoint) / (norm * direction)\n",
    "    fft_coeff = np.abs(fft(signal))[1:max_freq + 1] / signal.shape[0]\n",
    "    death = (2 * np.sqrt(3) * fft_coeff - endpoint) / (norm * direction)\n",
    "    return np.vstack([birth, death]).T\n",
    "\n",
    "\n",
    "def build_persistence_features(signals, direction, endpoint, resolution):\n",
    "    diagrams = [compute_persistence_diagram(signal, direction, endpoint) for signal in signals]\n",
    "    max_value = max(diag[:, 1].max() for diag in diagrams)\n",
    "\n",
    "    imager = PersistenceImage(\n",
    "        bandwidth=0.05,\n",
    "        weight=lambda x: x[1],\n",
    "        resolution=[resolution, resolution],\n",
    "        im_range=[0, max_value, 0, max_value],\n",
    "    )\n",
    "\n",
    "    features = np.array([imager(diagram) for diagram in diagrams])\n",
    "    min_vals = features.min(axis=1, keepdims=True)\n",
    "    max_vals = features.max(axis=1, keepdims=True)\n",
    "    denom = np.clip(max_vals - min_vals, 1e-12, None)\n",
    "    normalized = (features - min_vals) / denom\n",
    "    return diagrams, normalized\n",
    "\n",
    "\n",
    "diagrams, persistence_features = build_persistence_features(\n",
    "    data,\n",
    "    PERSISTENCE_DIRECTION,\n",
    "    PERSISTENCE_ENDPOINT,\n",
    "    PERSISTENCE_RESOLUTION,\n",
    ")\n",
    "print(persistence_features.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(\n",
    "    n_clusters=N_CLUSTERS,\n",
    "    init=\"random\",\n",
    "    n_init=100,\n",
    "    max_iter=300,\n",
    "    tol=1e-4,\n",
    "    random_state=0,\n",
    ")\n",
    "cluster_labels = kmeans.fit_predict(persistence_features)\n",
    "cluster_labels[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cluster_confusion(y_true, y_pred, subject_names):\n",
    "    n_classes = len(subject_names)\n",
    "    n_clusters = len(np.unique(y_pred))\n",
    "    matrix = np.zeros((n_classes, n_clusters), dtype=int)\n",
    "\n",
    "    for class_idx in range(n_classes):\n",
    "        for cluster_idx in range(n_clusters):\n",
    "            matrix[class_idx, cluster_idx] = np.sum((y_true == class_idx) & (y_pred == cluster_idx))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6, 4))\n",
    "    im = ax.imshow(matrix, cmap=\"summer\")\n",
    "    ax.set_xticks(range(n_clusters))\n",
    "    ax.set_xlabel(\"Cluster\")\n",
    "    ax.set_yticks(range(n_classes))\n",
    "    ax.set_yticklabels(subject_names)\n",
    "    ax.set_ylabel(\"True label\")\n",
    "    ax.set_title(\"Cluster vs. true label\")\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        for j in range(n_clusters):\n",
    "            ax.text(j, i, matrix[i, j], ha=\"center\", va=\"center\", color=\"black\")\n",
    "\n",
    "    fig.colorbar(im, ax=ax, shrink=0.8, pad=0.02)\n",
    "    plt.tight_layout()\n",
    "    return matrix\n",
    "\n",
    "\n",
    "confusion = plot_cluster_confusion(labels, cluster_labels, SUBJECTS)\n",
    "confusion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_indices = np.where(labels == STAR_LABEL)[0]\n",
    "star_cluster_counts = np.bincount(cluster_labels[star_indices], minlength=N_CLUSTERS)\n",
    "top_clusters = np.argsort(star_cluster_counts)[-2:][::-1]\n",
    "\n",
    "star_group_a = np.where((labels == STAR_LABEL) & (cluster_labels == top_clusters[0]))[0]\n",
    "star_group_b = np.where((labels == STAR_LABEL) & (cluster_labels == top_clusters[1]))[0]\n",
    "\n",
    "print(\"Top clusters for 'star':\", top_clusters)\n",
    "print(\"Group A size:\", len(star_group_a))\n",
    "print(\"Group B size:\", len(star_group_b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_signal_group(ax, dataset, indices, title, color):\n",
    "    if len(indices) == 0:\n",
    "        ax.set_title(f\"{title} (empty)\")\n",
    "        ax.axis(\"off\")\n",
    "        return\n",
    "    subset = dataset[indices[: min(len(indices), 9)]]\n",
    "    ax.plot(subset.T, color=color, alpha=0.3)\n",
    "    ax.set_title(f\"{title} (n={len(indices)})\")\n",
    "    ax.set_xlabel(\"Sample index (θ)\")\n",
    "    ax.set_ylabel(\"Radius\")\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4), sharey=True)\n",
    "plot_signal_group(axes[0], data, star_group_a, \"Star cluster A\", \"tomato\")\n",
    "plot_signal_group(axes[1], data, star_group_b, \"Star cluster B\", \"royalblue\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def harmonic_amplitude(dataset, indices, harmonic):\n",
    "    if len(indices) == 0:\n",
    "        return np.array([])\n",
    "    coeff = np.abs(fft(dataset[indices], axis=1))[:, harmonic]\n",
    "    return coeff / dataset.shape[1]\n",
    "\n",
    "\n",
    "harmonic_index = 5\n",
    "amp_a = harmonic_amplitude(data, star_group_a, harmonic_index)\n",
    "amp_b = harmonic_amplitude(data, star_group_b, harmonic_index)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "axes[0].scatter(\n",
    "    np.ones_like(amp_a) + 0.05 * np.random.randn(len(amp_a)),\n",
    "    amp_a,\n",
    "    color=\"tomato\",\n",
    "    alpha=0.6,\n",
    "    label=\"Cluster A\",\n",
    ")\n",
    "axes[0].scatter(\n",
    "    2 * np.ones_like(amp_b) + 0.05 * np.random.randn(len(amp_b)),\n",
    "    amp_b,\n",
    "    color=\"royalblue\",\n",
    "    alpha=0.6,\n",
    "    label=\"Cluster B\",\n",
    ")\n",
    "axes[0].set_xticks([1, 2])\n",
    "axes[0].set_xticklabels([\"Cluster A\", \"Cluster B\"])\n",
    "axes[0].set_ylabel(f\"Harmonic {harmonic_index} amplitude\")\n",
    "axes[0].set_title(\"Per-sample amplitudes\")\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].hist(amp_a, bins=15, alpha=0.6, color=\"tomato\", density=True, label=\"Cluster A\")\n",
    "axes[1].hist(amp_b, bins=15, alpha=0.6, color=\"royalblue\", density=True, label=\"Cluster B\")\n",
    "axes[1].set_xlabel(f\"Harmonic {harmonic_index} amplitude\")\n",
    "axes[1].set_ylabel(\"Density\")\n",
    "axes[1].set_title(\"Amplitude distribution\")\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recolor_star_for_display(img_rgb, *, cmap_name=\"Set3\", color_idx=0, alpha=0.9, edge=False, ax=None):\n",
    "    img = img_rgb.astype(np.float32).copy()\n",
    "    if img.max() > 1.0:\n",
    "        img /= 255.0\n",
    "\n",
    "    gray = rgb2gray(img)\n",
    "    thr = threshold_otsu(gray)\n",
    "    mask = gray < thr\n",
    "\n",
    "    cmap = plt.colormaps[cmap_name]\n",
    "    color = np.array(cmap(color_idx % cmap.N)[:3], dtype=np.float32).reshape(1, 1, 3)\n",
    "    img[mask] = (1 - alpha) * img[mask] + alpha * color\n",
    "\n",
    "    if edge and ax is not None:\n",
    "        contours = measure.find_contours(mask.astype(float), 0.5)\n",
    "        for cnt in contours:\n",
    "            ax.plot(cnt[:, 1], cnt[:, 0], lw=1.2, color=\"k\", alpha=0.8)\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "def to_rgb(arr):\n",
    "    arr = np.asarray(arr)\n",
    "    if arr.ndim == 2:\n",
    "        arr = np.stack([arr] * 3, axis=-1)\n",
    "    if arr.ndim == 3 and arr.shape[2] == 4:\n",
    "        arr = arr[..., :3]\n",
    "    return arr\n",
    "\n",
    "\n",
    "def draw_leaf(path):\n",
    "    img = mpimg.imread(path)\n",
    "    if img.dtype not in (np.float32, np.float64):\n",
    "        img = img.astype(np.float32) / 255.0\n",
    "    h, w = img.shape[:2]\n",
    "    return img, (w / 2.0, h / 2.0)\n",
    "\n",
    "\n",
    "def cohens_d(x, y):\n",
    "    x = np.asarray(x)\n",
    "    y = np.asarray(y)\n",
    "    if len(x) < 2 or len(y) < 2:\n",
    "        return np.nan\n",
    "    sx = np.var(x, ddof=1)\n",
    "    sy = np.var(y, ddof=1)\n",
    "    sp = np.sqrt(((len(x) - 1) * sx + (len(y) - 1) * sy) / (len(x) + len(y) - 2))\n",
    "    return (np.mean(y) - np.mean(x)) / sp if sp > 0 else np.nan\n",
    "\n",
    "\n",
    "def measure_with_regionprops(img_rgb, *, spacing=None):\n",
    "    gray = rgb2gray(img_rgb)\n",
    "    thr = threshold_otsu(gray)\n",
    "    mask = gray < thr\n",
    "    lab = sk_label(mask)\n",
    "    if lab.max() == 0:\n",
    "        return None\n",
    "\n",
    "    props = [\n",
    "        \"label\",\n",
    "        \"area\",\n",
    "        \"area_bbox\",\n",
    "        \"area_convex\",\n",
    "        \"area_filled\",\n",
    "        \"axis_major_length\",\n",
    "        \"axis_minor_length\",\n",
    "        \"eccentricity\",\n",
    "        \"equivalent_diameter_area\",\n",
    "        \"euler_number\",\n",
    "        \"extent\",\n",
    "        \"feret_diameter_max\",\n",
    "        \"orientation\",\n",
    "        \"perimeter_crofton\",\n",
    "        \"perimeter\",\n",
    "        \"solidity\",\n",
    "        \"centroid\",\n",
    "        \"centroid_local\",\n",
    "    ]\n",
    "\n",
    "    table = regionprops_table(lab, intensity_image=gray, spacing=spacing, properties=props)\n",
    "    df_props = pd.DataFrame(table)\n",
    "    if df_props.empty:\n",
    "        return None\n",
    "\n",
    "    row = df_props.loc[df_props[\"area\"].idxmax()].to_dict()\n",
    "\n",
    "    result = {k: (float(v) if np.isscalar(v) else v) for k, v in row.items()}\n",
    "    result[\"eq_radius\"] = float(np.sqrt(result[\"area\"] / np.pi))\n",
    "    orientation = result.get(\"orientation\", 0.0)\n",
    "    result[\"angle_deg\"] = float(np.degrees(orientation) % 180.0)\n",
    "\n",
    "    h, w = img_rgb.shape[:2]\n",
    "    tcx, tcy = w / 2.0, h / 2.0\n",
    "    cx = result.get(\"centroid-1\", np.nan)\n",
    "    cy = result.get(\"centroid-0\", np.nan)\n",
    "    off_x = cx - tcx\n",
    "    off_y = cy - tcy\n",
    "    result[\"off_x\"] = float(off_x)\n",
    "    result[\"off_y\"] = float(off_y)\n",
    "    result[\"r_off\"] = float(np.hypot(off_x, off_y))\n",
    "    return result\n",
    "\n",
    "\n",
    "def summarize_and_test(df, metric, *, group_col=\"group\", groups=(\"cluster_a\", \"cluster_b\")):\n",
    "    left = df.loc[df[group_col] == groups[0], metric].dropna().values\n",
    "    right = df.loc[df[group_col] == groups[1], metric].dropna().values\n",
    "    if len(left) < 2 or len(right) < 2:\n",
    "        return pd.Series({\n",
    "            \"left_mean\": np.nan,\n",
    "            \"left_std\": np.nan,\n",
    "            \"right_mean\": np.nan,\n",
    "            \"right_std\": np.nan,\n",
    "            \"diff_right_minus_left\": np.nan,\n",
    "            \"p_value\": np.nan,\n",
    "            \"cohens_d\": np.nan,\n",
    "        })\n",
    "\n",
    "    t_stat, p_val = ttest_ind(right, left, equal_var=False)\n",
    "    series = pd.Series({\n",
    "        \"left_mean\": left.mean(),\n",
    "        \"left_std\": left.std(ddof=1),\n",
    "        \"right_mean\": right.mean(),\n",
    "        \"right_std\": right.std(ddof=1),\n",
    "        \"diff_right_minus_left\": right.mean() - left.mean(),\n",
    "        \"p_value\": p_val,\n",
    "        \"cohens_d\": cohens_d(left, right),\n",
    "    })\n",
    "    return series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STAR_DIR = os.path.join(SHAPES_ROOT, \"star\")\n",
    "star_samples_a = np.sort(sample_ids[star_group_a])[:9]\n",
    "star_samples_b = np.sort(sample_ids[star_group_b])[:9]\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "outer = gridspec.GridSpec(2, 1, height_ratios=[1, 1])\n",
    "\n",
    "records = []\n",
    "\n",
    "inner_a = gridspec.GridSpecFromSubplotSpec(3, 3, subplot_spec=outer[0])\n",
    "for ax_idx, sample in enumerate(star_samples_a):\n",
    "    ax = fig.add_subplot(inner_a[ax_idx])\n",
    "    path = os.path.join(STAR_DIR, f\"{int(sample)}.png\")\n",
    "    img, _ = draw_leaf(path)\n",
    "    img = to_rgb(img)\n",
    "    disp = recolor_star_for_display(img, cmap_name=\"Set3\", color_idx=0, alpha=0.95, edge=True, ax=ax)\n",
    "    ax.imshow(disp)\n",
    "    ax.set_title(f\"A-{int(sample)}\")\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "    metrics = measure_with_regionprops(img)\n",
    "    if metrics:\n",
    "        metrics.update(group=\"cluster_a\", sample=int(sample))\n",
    "        records.append(metrics)\n",
    "\n",
    "inner_b = gridspec.GridSpecFromSubplotSpec(3, 3, subplot_spec=outer[1])\n",
    "for ax_idx, sample in enumerate(star_samples_b):\n",
    "    ax = fig.add_subplot(inner_b[ax_idx])\n",
    "    path = os.path.join(STAR_DIR, f\"{int(sample)}.png\")\n",
    "    img, _ = draw_leaf(path)\n",
    "    img = to_rgb(img)\n",
    "    disp = recolor_star_for_display(img, cmap_name=\"Set3\", color_idx=4, alpha=0.95, edge=True, ax=ax)\n",
    "    ax.imshow(disp)\n",
    "    ax.set_title(f\"B-{int(sample)}\")\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "    metrics = measure_with_regionprops(img)\n",
    "    if metrics:\n",
    "        metrics.update(group=\"cluster_b\", sample=int(sample))\n",
    "        records.append(metrics)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "metrics_df = pd.DataFrame(records)\n",
    "metrics_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_to_report = [\n",
    "    \"eq_radius\",\n",
    "    \"axis_major_length\",\n",
    "    \"axis_minor_length\",\n",
    "    \"eccentricity\",\n",
    "    \"solidity\",\n",
    "    \"extent\",\n",
    "    \"perimeter\",\n",
    "    \"perimeter_crofton\",\n",
    "    \"feret_diameter_max\",\n",
    "    \"equivalent_diameter_area\",\n",
    "    \"euler_number\",\n",
    "    \"r_off\",\n",
    "    \"angle_deg\",\n",
    "]\n",
    "\n",
    "summary = pd.concat(\n",
    "    [summarize_and_test(metrics_df, metric) for metric in metrics_to_report],\n",
    "    axis=1,\n",
    ").T\n",
    "summary = summary.sort_values(\"p_value\")\n",
    "summary.round(3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}